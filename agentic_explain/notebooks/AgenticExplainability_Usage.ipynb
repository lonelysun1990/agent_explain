{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Explainability Workflow â€“ Usage\n",
    "\n",
    "This notebook runs the agentic explainability pipeline: ask a natural-language question about optimization results, get a counterfactual run and a summary (trade-offs or infeasibility conflict).\n",
    "\n",
    "**Prerequisites:**\n",
    "- `config/secrets.env` with `OPENAI_API_KEY` and `GUROBI_LICENSE_FILE=config/WLS-dev-key.lic`\n",
    "- Run the first two sections once to create the baseline and RAG index; then you can run only the workflow section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup paths and load secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root: directory that contains agentic_explain and data\n",
    "def find_project_root():\n",
    "    for start in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        if (start / \"agentic_explain\").is_dir() and (start / \"data\").is_dir():\n",
    "            return start\n",
    "    return Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from config.load_secrets import load_secrets, get_gurobi_env_kwargs\n",
    "\n",
    "load_secrets()  # load from config/secrets.env or project root\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run baseline (once)\n",
    "\n",
    "Saves `outputs/baseline_result.json`, `outputs/model.lp`, `outputs/model.mps`. Skip this cell if you already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gurobipy import GRB\n",
    "\n",
    "from agentic_explain.staffing_model import load_raw_data, process_data, build_gurobi_model\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw = load_raw_data(DATA_DIR)\n",
    "inputs = process_data(\n",
    "    raw[\"fte_mapping\"],\n",
    "    raw[\"concurrent_projects\"],\n",
    "    raw[\"oversight_ds_list\"],\n",
    "    raw[\"ds_list\"],\n",
    "    raw[\"project_list\"],\n",
    ")\n",
    "env_kwargs = get_gurobi_env_kwargs()\n",
    "model = build_gurobi_model(inputs, env_kwargs)\n",
    "model.setParam(GRB.Param.TimeLimit, 100)\n",
    "model.optimize()\n",
    "\n",
    "if model.status in (GRB.OPTIMAL, GRB.TIME_LIMIT):\n",
    "    baseline_result = {\n",
    "        \"status\": \"optimal\" if model.status == GRB.OPTIMAL else \"time_limit\",\n",
    "        \"objective_value\": model.ObjVal,\n",
    "        \"decision_variables\": {v.VarName: v.X for v in model.getVars()},\n",
    "    }\n",
    "    with open(OUTPUTS_DIR / \"baseline_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(baseline_result, f, indent=2)\n",
    "    model.write(str(OUTPUTS_DIR / \"model.lp\"))\n",
    "    model.write(str(OUTPUTS_DIR / \"model.mps\"))\n",
    "    print(\"Baseline saved to\", OUTPUTS_DIR)\n",
    "else:\n",
    "    print(\"Model status:\", model.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build RAG index (once)\n",
    "\n",
    "Builds `outputs/rag_index/` from the formulation .py, .lp, .mps, and data. Skip if already built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_explain.rag.build_index import build_rag_index\n",
    "\n",
    "py_path = PROJECT_ROOT / \"agentic_explain\" / \"staffing_model.py\"\n",
    "lp_path = OUTPUTS_DIR / \"model.lp\"\n",
    "mps_path = OUTPUTS_DIR / \"model.mps\"\n",
    "\n",
    "build_rag_index(\n",
    "    py_path=py_path,\n",
    "    lp_path=lp_path if lp_path.exists() else None,\n",
    "    mps_path=mps_path if mps_path.exists() else None,\n",
    "    data_dir=DATA_DIR,\n",
    "    persist_dir=OUTPUTS_DIR / \"rag_index\",\n",
    ")\n",
    "print(\"RAG index built at\", OUTPUTS_DIR / \"rag_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the workflow\n",
    "\n",
    "Load baseline and RAG index, then run the agentic workflow for a natural-language query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from agentic_explain.staffing_model import build_gurobi_model\n",
    "from agentic_explain.rag.build_index import load_rag_index\n",
    "from agentic_explain.workflow.graph import create_workflow, invoke_workflow\n",
    "\n",
    "# Load baseline and RAG index\n",
    "with open(OUTPUTS_DIR / \"baseline_result.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    baseline_result = json.load(f)\n",
    "\n",
    "rag_index = load_rag_index(persist_dir=OUTPUTS_DIR / \"rag_index\")\n",
    "openai_client = OpenAI()\n",
    "\n",
    "workflow = create_workflow(\n",
    "    openai_client=openai_client,\n",
    "    rag_index=rag_index,\n",
    "    baseline_result=baseline_result,\n",
    "    data_dir=str(DATA_DIR),\n",
    "    build_model_fn=build_gurobi_model,\n",
    "    inputs=inputs,\n",
    "    env_kwargs=env_kwargs,\n",
    "    outputs_dir=str(OUTPUTS_DIR),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query: counterfactual (\"why not\")\n",
    "user_query = \"Why was Josh not staffed on Ipp IO Pilot in week 6?\"\n",
    "\n",
    "final_state = invoke_workflow(\n",
    "    workflow,\n",
    "    user_query,\n",
    "    baseline_result=baseline_result,\n",
    "    rag_index=rag_index,\n",
    ")\n",
    "\n",
    "print(\"Query:\", user_query)\n",
    "print()\n",
    "print(\"Summary:\")\n",
    "print(final_state.get(\"final_summary\", \"(no summary)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try another query (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct instruction example\n",
    "user_query2 = \"Force Josh to be staffed on Ipp IO Pilot in week 6\"\n",
    "\n",
    "final_state2 = invoke_workflow(\n",
    "    workflow,\n",
    "    user_query2,\n",
    "    baseline_result=baseline_result,\n",
    "    rag_index=rag_index,\n",
    ")\n",
    "\n",
    "print(\"Query:\", user_query2)\n",
    "print()\n",
    "print(final_state2.get(\"final_summary\", \"(no summary)\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
